{
 "metadata": {
  "name": "",
  "signature": "sha256:540223df8e5196e94620d307be959babb297e6f53ada817c022800cce2c05e63"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Author: Miriam Heller <mheller8@gatech.edu> after Gael Varoquaux\n",
      "\n",
      "# Standard scientific Python imports\n",
      "import numpy as np\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from sklearn import cross_validation\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "# Import digits dataset\n",
      "from sklearn.datasets import load_digits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "# Goal: Apply the k-NN classifier to two datasets. Evaluate the models while varying hyperparameter values.\n",
      "# Learn how to select the best model for each algorithm and dataset. Compare the performance of the k-NN\n",
      "# algorithm on the different dataset and determine whether one type of data was more amenable to the\n",
      "# algorithm than the other. Through analysis speculate or explain why.\n",
      "# \n",
      "# Dataset 1 = the sci-kit subset of the MNIST database of handwritten digits 0-9. This subset consists of \n",
      "# 1797 samples with each digit depicted/store as 8x8 16 grey-scale # images. Thus each sample has 64 \n",
      "# features. \n",
      "#\n",
      "# Parameters to vary for model selection:\n",
      "#\n",
      "# \u2022 k - number of nearest neighbors to use to estimate target \n",
      "#\n",
      "# \u2022 Learning (Split on training/CV/test) - 70%/30%, 80%/20%, 85%/15%, 90%/10% training/test set scheme.\n",
      "#   Reduce overfitting by constraining minimum samples_split to 5% of sample to be fit (90%). \n",
      "#\n",
      "# \u2022 d(x,q) - definition of distance, e.g., Manhatten, Euclidean, Distance-Weighted, etc.  \n",
      "#\n",
      "# Models will be evaluated and selected based on the analysis of the results of parameter variation in\n",
      "# terms of bias, variance and learning curves.\n",
      "#"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exploratory data analysis to verify dataset\n",
      "#\n",
      "# Load MNIST digit data and verify dimensions\n",
      "data_set_name = \"MNIST Digit Dataset\"\n",
      "digits = load_digits()\n",
      "samples = digits.data.shape[0]\n",
      "features = digits.data.shape[1]\n",
      "classes = digits.target_names.shape[0]\n",
      "print samples\n",
      "print features\n",
      "print classes\n",
      "print digits.target_names\n",
      "print digits.data[1:2]\n",
      "print digits.target.shape[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab as pl \n",
      "pl.matshow(digits.images[100])\n",
      "print digits.target[100]\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Separate data into randomly selected training/validation and test\n",
      "# sets keeping the test set for final model testing. * Since the iris\n",
      "# data is so small will do a K-fold cv but will still do final\n",
      "# test for some percent reserved for hold_out.*\n",
      "#\n",
      "hold_out =.4\n",
      "rand = 42\n",
      "X_train, X_holdout, y_train, y_holdout = cross_validation.train_test_split(\n",
      "    digits.data, digits.target, test_size=hold_out, random_state=rand)\n",
      "# Split holdout evenly into a cross-validation set and a final test set\n",
      "X_CV, X_test, y_CV, y_test = cross_validation.train_test_split(\n",
      "    X_holdout, y_holdout, test_size=.5, random_state=rand)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'samples = ', digits.data.shape[0]\n",
      "print 'features = ', digits.data.shape[1]\n",
      "print 'targets = ', digits.target.shape[0]\n",
      "#print 'classes = ', digits.target_names.shape[0]\n",
      "#print 'X_train=', X_train\n",
      "#print 'y_train=', y_train\n",
      "print X_train.shape\n",
      "print y_train.shape\n",
      "print X_CV.shape\n",
      "print y_CV.shape\n",
      "print X_test.shape\n",
      "print y_test.shape[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, train the model, using a fixed n\n",
      "\n",
      "neigh = KNeighborsClassifier(n_neighbors=30)\n",
      "neigh.fit(X_train,y_train) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_pred = neigh.predict(X_test)\n",
      "print y_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.histogram(y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(np.histogram(y_test)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "confusion_matrix(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum(confusion_matrix(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print y_test\n",
      "# print len(y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print y_pred\n",
      "# print len(y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_score(y_test, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_k = int(np.floor(y_test.shape[0] * 0.1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print max_k"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}