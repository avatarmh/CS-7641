{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Explorations of k-NN\n",
    "\n",
    "# Author: Miriam Heller <mheller8@gatech.edu>\n",
    "# CS 7641, Spring\n",
    "\n",
    "# Application to the sk-learns's built in 0-9 digit dataset\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import digits dataset\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Goal: Apply the k-NN classifier to two datasets. Evaluate the models while varying hyperparameter values.\n",
    "# Learn how to select the best model for each algorithm and dataset. Compare the performance of the k-NN\n",
    "# algorithm on the different dataset and determine whether one type of data was more amenable to the\n",
    "# algorithm than the other. Through analysis speculate or explain why.\n",
    "#\n",
    "# Dataset 1 = the sci-kit subset of the MNIST database of handwritten digits 0-9. This subset consists of\n",
    "# 1797 samples with each digit depicted/store as 8x8 16 grey-scale # images. Thus each sample has 64\n",
    "# features.\n",
    "#\n",
    "# Parameters to vary for model selection:\n",
    "#\n",
    "#  k - number of nearest neighbors to use to estimate target\n",
    "#\n",
    "#  Learning (Split on training/CV/test) - 70%/30%, 80%/20%, 85%/15%, 90%/10% training/test set scheme.\n",
    "#   Reduce overfitting by constraining minimum samples_split to 5% of sample to be fit (90%).\n",
    "#\n",
    "#  d(x,q) - definition of distance, e.g., Manhatten, Euclidean, Distance-Weighted, etc.\n",
    "#\n",
    "# Models will be evaluated and selected based on the analysis of the results of parameter variation in\n",
    "# terms of bias, variance and learning curves.\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "64\n",
      "10\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[[  0.   0.   0.  12.  13.   5.   0.   0.   0.   0.   0.  11.  16.   9.\n",
      "    0.   0.   0.   0.   3.  15.  16.   6.   0.   0.   0.   7.  15.  16.\n",
      "   16.   2.   0.   0.   0.   0.   1.  16.  16.   3.   0.   0.   0.   0.\n",
      "    1.  16.  16.   6.   0.   0.   0.   0.   1.  16.  16.   6.   0.   0.\n",
      "    0.   0.   0.  11.  16.  10.   0.   0.]]\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "# Exploratory data analysis to verify dataset\n",
    "#\n",
    "# Load MNIST digit data and verify dimensions\n",
    "data_set_name = \"MNIST Digit Dataset\"\n",
    "digits = load_digits()\n",
    "samples = digits.data.shape[0]\n",
    "features = digits.data.shape[1]\n",
    "classes = digits.target_names.shape[0]\n",
    "print samples\n",
    "print features\n",
    "print classes\n",
    "print digits.target_names\n",
    "print digits.data[1:2]\n",
    "print digits.target.shape[0]\n",
    "\n",
    "# Print out examples for 0 - 9 from dataset for report\n",
    "# import pylab as pl\n",
    "# pl.matshow(digits.images[12], cmap = pl.cm.gray)\n",
    "# print digits.target[12]\n",
    "# pl.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples =  1797\n",
      "features =  64\n",
      "targets =  1797\n",
      "Train_set_size= 1078\n",
      "Validation_set_size= 359\n",
      "Test_set_size= 360\n"
     ]
    }
   ],
   "source": [
    "# Separate data into randomly selected training/validation and test\n",
    "# sets keeping the test set for final model testing. * Since the iris\n",
    "# data is so small will do a K-fold cv but will still do final\n",
    "# test for some percent reserved for hold_out.*\n",
    "#\n",
    "hold_out =.4\n",
    "rand = 42\n",
    "X_train, X_holdout, y_train, y_holdout = cross_validation.train_test_split(\n",
    "    digits.data, digits.target, test_size=hold_out, random_state=rand)\n",
    "# Split holdout evenly into a cross-validation set and a final test set\n",
    "X_CV, X_test, y_CV, y_test = cross_validation.train_test_split(\n",
    "    X_holdout, y_holdout, test_size=.5, random_state=rand)\n",
    "\n",
    "# Verify sample sizes\n",
    "\n",
    "print 'samples = ', digits.data.shape[0]\n",
    "print 'features = ', digits.data.shape[1]\n",
    "print 'targets = ', digits.target.shape[0]\n",
    "print 'Train_set_size=', X_train.shape[0]\n",
    "print 'Validation_set_size=', X_CV.shape[0]\n",
    "print 'Test_set_size=', X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training set, varying k\n",
    "# Simultaneously calculate the mean accuracy of each model defined by k on the test & validation set data\n",
    "\n",
    "# Test models for k = 1,max_k_train = 10% of training set size\n",
    "\n",
    "accuracy_scores_train = []\n",
    "accuracy_scores_CV = []\n",
    "ks = []\n",
    "\n",
    "for i in range(15):\n",
    "\n",
    "    ks.append(i+1)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i+1)\n",
    "    neigh.fit(X_train,y_train)\n",
    "\n",
    "# Predict class for each example in training set (for fixed k) and calculate corresponding accuracy\n",
    "#    accuracy_scores_train.append(accuracy_score(y_train, neigh.predict(X_train)))\n",
    "\n",
    "# Predict class for each example in validation set (for fixed k) and calculate corresponding accuracy\n",
    "    accuracy_scores_CV.append(accuracy_score(y_CV, neigh.predict(X_CV)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN_MNIST Digit Dataset_train1078.csv\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Accuracy scores based on training []\n",
      "Accuracy scores based on validation [0.98328690807799446, 0.98607242339832868, 0.9888579387186629, 0.99164345403899723, 0.98607242339832868, 0.98607242339832868, 0.98328690807799446, 0.98328690807799446, 0.98328690807799446, 0.98328690807799446, 0.98050139275766013, 0.98050139275766013, 0.98050139275766013, 0.98050139275766013, 0.97771587743732591]\n",
      "Optimal model: k= 4 Maximum accuracy =  0.991666666667\n"
     ]
    }
   ],
   "source": [
    "train_size = str(X_train.shape[0])\n",
    "\n",
    "filename = \"kNN_\" + data_set_name + \"_train\" + train_size + \".csv\"\n",
    "\n",
    "# Choose the ks associated with the optimal accuracy_score over all k\n",
    "\n",
    "k_max = np.argmax(accuracy_scores_CV) + 1\n",
    "\n",
    "# Predict y_test using training set according to find optimal k from validation set\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=k_max)\n",
    "neigh.fit(X_train,y_train)\n",
    "\n",
    "# Compare accuracy of of optimal model defined by optimal k and training set using the test set\n",
    "\n",
    "test_set_accuracy = accuracy_score(y_test, neigh.predict(X_test))\n",
    "\n",
    "print filename\n",
    "\n",
    "print ks\n",
    "\n",
    "\n",
    "print 'Accuracy scores based on training', accuracy_scores_train\n",
    "print 'Accuracy scores based on validation', accuracy_scores_CV\n",
    "\n",
    "print 'Optimal model: k=', k_max, \"Maximum accuracy = \", test_set_accuracy\n",
    "\n",
    "#np.savetxt(filename,'Optimal model: k=', k_max, ' and maximal accuracy = ', test_set_accuracy)\n",
    "np.savetxt(filename,zip(ks,accuracy_scores_train,accuracy_scores_CV),delimiter=',')\n",
    "\n",
    "\n",
    "# fini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
